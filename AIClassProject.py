import pandas as pd
import numpy as np
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV  # <-- Using GridSearchCV
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, precision_recall_curve
import matplotlib.pyplot as plt
import time

# Start time
start_time = time.time()

# Load and process the data
sample_data = pd.read_csv('wustl_iiot_2021.csv')
pd.set_option('display.max_columns', None)
print(sample_data.head(2))

sample_data_01_percent = sample_data.sample(frac=0.001)
print(sample_data_01_percent.shape)

X = sample_data_01_percent.drop(columns=['Target', 'Traffic', 'StartTime', 'LastTime', 'SrcAddr', 'DstAddr', 'Sport', 'Dport', 'sTos'])
y = sample_data_01_percent['Target']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)

# Data Visualization
def plot_feature_distributions(data, num_columns):
    plt.figure(figsize=(15, 12))
    for i, col in enumerate(num_columns):
        plt.subplot(len(num_columns) // 3 + 1, 3, i + 1)
        sns.histplot(data[col], kde=True)
        plt.title(f'Distribution of {col}')
        plt.tight_layout()
    plt.show()

plot_feature_distributions(sample_data_01_percent, sample_data_01_percent.select_dtypes(include=['int64', 'float64']).columns[:9])

# Feature Correlation Analysis
# Select only numeric columns for the correlation matrix
numeric_data_sample = sample_data_01_percent.select_dtypes(include=[np.number])
plt.figure(figsize=(15, 18))
sns.heatmap(numeric_data_sample.corr(), annot=True, cmap='coolwarm', fmt='.0f')
plt.title("Feature Correlation Heatmap")
plt.show()

# Feature Importance for Random Forest
def plot_feature_importance(model, feature_names):
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]
    plt.figure(figsize=(10, 6))
    sns.barplot(x=importances[indices], y=feature_names[indices])
    plt.title('Feature Importances in Random Forest')
    plt.show()

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define hyperparameters
param_dist_log_reg = {
    'solver': ['saga', 'liblinear'],
    'max_iter': [1000, 5000],
    'C': [ 1, 10, 100],
    'tol': [1e-3, 1e-2]
}

param_dist_svm = {
    'C': [ 1, 10, 100],
    'kernel': ['linear', 'rbf'],
    'gamma': ['scale', 'auto', 0.1, 1, 10],
}

param_dist_rf = {
    'n_estimators': [100, 200],
    'max_depth': [None, 5, 7],
    'min_samples_split': [2, 5],
    'min_samples_leaf': [1, 2],
    'bootstrap': [True, False]
}

# Create grid search objects
grid_search_log_reg = GridSearchCV(LogisticRegression(), param_grid=param_dist_log_reg, cv=5, verbose=3,  n_jobs=-1)
grid_search_svm = GridSearchCV(SVC(probability=True), param_grid=param_dist_svm, cv=5, verbose=3,  n_jobs=-1)
grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid=param_dist_rf, cv=5, verbose=3,  n_jobs=-1)

# Train the models using grid search
grid_search_log_reg.fit(X_train, y_train)
grid_search_svm.fit(X_train, y_train)
grid_search_rf.fit(X_train, y_train)

# Extract best models
best_log_reg = grid_search_log_reg.best_estimator_
best_svm = grid_search_svm.best_estimator_
best_rf = grid_search_rf.best_estimator_

# Predict using the best models
log_reg_pred = best_log_reg.predict(X_test)
svm_pred = best_svm.predict(X_test)
rf_pred = best_rf.predict(X_test)

# Call this function after training the Random Forest model
plot_feature_importance(best_rf, X.columns)

# Accuracy
print("Logistic Regression Accuracy:", accuracy_score(y_test, log_reg_pred))
print("SVM Accuracy:", accuracy_score(y_test, svm_pred))
print("Random Forest Accuracy:", accuracy_score(y_test, rf_pred))

# Print best parameters and scores
print("Best Parameters for Logistic Regression:", grid_search_log_reg.best_params_)
print("Best Score for Logistic Regression:", grid_search_log_reg.best_score_)
print("\nBest Parameters for SVM:", grid_search_svm.best_params_)
print("Best Score for SVM:", grid_search_svm.best_score_)
print("\nBest Parameters for Random Forest:", grid_search_rf.best_params_)
print("Best Score for Random Forest:", grid_search_rf.best_score_)


# End time
end_time = time.time()

# Calculate total time taken
total_time_log_reg = end_time - start_time

# Convert total time to hours, minutes, and seconds
hours, remainder = divmod(total_time_log_reg, 3600)
minutes, seconds = divmod(remainder, 60)

print(f"Time taken for the training: {int(hours)} hours, {int(minutes)} minutes, and {seconds:.2f} seconds")

# Plotting functions
def plot_confusion_matrix(y_true, y_pred, title):
    labels = ['Not attacked', 'attacked']
    cm = confusion_matrix(y_true, y_pred)
    plt.figure(figsize=(7, 5))
    ax = plt.subplot()
    sns.heatmap(cm, cmap="Blues", annot=True, fmt='.1f', ax=ax)
    ax.set_xticklabels(labels)
    ax.set_yticklabels(labels)
    ax.set_xlabel('Predicted labels')
    ax.set_ylabel('True labels')
    ax.set_title(title)
    plt.show()

def plot_roc_curve(y_true, preds, labels):
    plt.figure(figsize=(8, 6))
    for i, pred in enumerate(preds):
        fpr, tpr, _ = roc_curve(y_true, pred)
        plt.plot(fpr, tpr, label=labels[i])
    plt.plot([0, 1], [0, 1],'r--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic')
    plt.legend(loc="lower right")
    plt.show()

def plot_precision_recall_curve(y_true, preds, labels):
    plt.figure(figsize=(8, 6))
    for i, pred in enumerate(preds):
        precision, recall, _ = precision_recall_curve(y_true, pred)
        plt.plot(recall, precision, label=labels[i])
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title('Precision-Recall Curve')
    plt.legend(loc="lower right")
    plt.show()

# Confusion matrices
plot_confusion_matrix(y_test, log_reg_pred, 'Confusion Matrix Logistic Regression')
plot_confusion_matrix(y_test, svm_pred, 'Confusion Matrix SVM')
plot_confusion_matrix(y_test, rf_pred, 'Confusion Matrix Random Forest')

# ROC curves
pred_probs = [best_log_reg.predict_proba(X_test)[:,1], best_svm.predict_proba(X_test)[:,1], best_rf.predict_proba(X_test)[:,1]]
labels = ['Logistic Regression', 'SVM', 'Random Forest']
plot_roc_curve(y_test, pred_probs, labels)

# Precision-Recall curves
plot_precision_recall_curve(y_test, pred_probs, labels)
